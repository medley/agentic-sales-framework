---
name: "POC/Pilot Play"
type: "sales_play"
owner: "{YOUR_NAME}"
version: "1.0.0"
license: "MIT - See LICENSE.md"
---

# POC/Pilot Play: Proof of Value & Pilot Structure

<triggers>
- technical_validation_needed (buyer wants to test before committing)
- stakeholder_skepticism (internal resistance, needs proof)
- competitive_bakeoff (evaluating multiple vendors)
- complex_use_case (unique requirements, need to validate fit)
- risk_averse_buyer (large investment, wants to de-risk)
- new_product_category (buyer unfamiliar with solution type)
</triggers>

<principles>
- **Success criteria first**: Define metrics upfront (before starting), not vague "see if it works"
- **Time-box ruthlessly**: 30-60 days max (pilots that drag = deals that die)
- **Charge when possible**: Paid pilots have commitment, free pilots get deprioritized
- **Plan the transition**: "What happens if pilot succeeds?" (pre-agree on next steps)
- **Scope control**: Fixed scope, no scope creep (kills timelines)
- **Executive sponsorship**: Pilot needs exec sponsor (not just champion), ensures resources
</principles>

<steps>
1. **Diagnose need for pilot**:
   - **Good reasons**: Technical validation, unique use case, risk mitigation, competitive bakeoff
   - **Bad reasons**: Buyer stalling, lack of urgency, avoiding decision (pilot = delay tactic)
   - **Test**: "If pilot succeeds, what's the path to full contract?" (if no clear answer = red flag)

2. **Define success criteria** (BEFORE pilot starts):
   - **Quantified metrics**: "Reduce process time from 10 days to 3 days" (not "improve efficiency")
   - **Business outcomes**: Revenue impact, cost savings, risk reduction (not technical metrics)
   - **Pass/fail threshold**: "If we hit X, we proceed. If not, we stop." (binary decision)
   - **Document in writing**: Pilot charter with success criteria signed by exec sponsor

3. **Scope the pilot**:
   - **Limited scope**: 1-2 use cases, 10-50 users, single department (not enterprise-wide)
   - **Time-box**: 30-60 days (4-8 weeks max). Longer = deal drag.
   - **Resources required**: Customer commits implementation team, not just "we'll try it when we have time"
   - **Deliverables**: Weekly check-ins, final readout with metrics

4. **Structure commercial terms**:
   - **Option 1 - Paid pilot**: $25K-$50K pilot fee, credited toward full contract if they proceed
   - **Option 2 - Free pilot with commitment**: Free pilot IF they commit to timeline and success criteria
   - **Option 3 - Vendor-funded**: Free pilot, but only if no other option (lowest commitment)
   - **Best practice**: Paid pilot > Free with commitment > Vendor-funded

5. **Execute pilot**:
   - **Week 1**: Kickoff, set up environment, train users
   - **Week 2-4**: Active usage, weekly check-ins, address issues
   - **Week 5-6**: Measure results, collect user feedback
   - **Week 7**: Final readout with exec sponsor, show success criteria results
   - **Week 8**: Contract negotiation (if success) or close-out (if failure)

6. **Transition to contract**:
   - **Success scenario**: Present results → exec approves → contract negotiation (pilot fee credited if paid)
   - **Failure scenario**: Diagnose why (scope, timing, fit), decide if salvageable or walk away
   - **Partial success**: Adjust scope or pricing, propose phased rollout
</steps>

<examples>
<example id="paid_pilot_saas">
**Context**: $800K SaaS deal, CIO wants to validate technical fit before committing

**Situation**: CIO says "I like this, but I need to see it work in our environment first"

**Pilot proposal**:
- **Duration**: 45 days
- **Scope**: Sales team (50 users), CRM integration, mobile access
- **Success criteria**:
  1. 80%+ user adoption (40+ of 50 users active weekly)
  2. 50% reduction in manual data entry time (measured via time tracking)
  3. Zero critical bugs or security incidents
- **Commercial terms**: $40K pilot fee, credited toward $800K contract if they proceed
- **Timeline**: Weeks 1-6 pilot, Week 7 readout, Week 8 contract if success

**Execution**:
- **Week 1**: Onboarded 50 sales reps, integrated with Salesforce CRM
- **Week 3 check-in**: 85% adoption (42 active users), early positive feedback
- **Week 5 check-in**: 88% adoption, time savings measured at 55% (exceeded goal)
- **Week 7 readout**: Presented results to CIO + VP Sales
  - Adoption: 88% (beat 80% target)
  - Time savings: 55% (beat 50% target)
  - Bugs: 2 minor, 0 critical (met criteria)

**Outcome**: CIO approved full $800K contract, $40K pilot fee credited

**Key moves**:
- Charged for pilot ($40K) = ensured customer commitment and resources
- Success criteria were quantified and binary (not subjective)
- Weekly check-ins caught issues early (adjusted training in Week 2)
- Final readout with metrics made approval easy (CIO had data to justify decision)
</example>

<example id="competitive_bakeoff">
**Context**: $1.2M deal, enterprise evaluating 3 vendors (us + 2 competitors)

**Situation**: Buying committee wants all 3 vendors to do 60-day pilots (bakeoff)

**Competitive pilot strategy**:
- **Our proposal**: 30-day pilot (vs competitors' 60 days = faster results)
- **Success criteria** (co-created with champion):
  1. Integrate with 5 enterprise systems (vs competitors promising 3)
  2. 90%+ uptime (SLA guarantee)
  3. Onboard 100 users in 2 weeks (vs competitors' 4 weeks)
- **Commercial terms**: Free pilot, but customer commits to decision in Week 5 (not open-ended)

**Competitive advantage**:
- **Faster timeline**: 30 days vs competitors' 60 days = we get results first
- **Higher bar**: Committed to 5 integrations vs competitors' 3 = showed confidence
- **Customer commitment**: Required decision deadline (competitors had open-ended pilots)

**Execution**:
- **Week 1**: Completed 5 integrations (competitors completed 1-2)
- **Week 2**: Onboarded 100 users (competitors onboarded 20-30)
- **Week 3**: Hit 99.2% uptime (competitors had downtime issues)
- **Week 4**: Collected user feedback (92% satisfaction)
- **Week 5**: Presented results (beat all success criteria)

**Competitor status**:
- Competitor A: Still in setup phase (technical issues)
- Competitor B: Onboarded 50 users, but 2 outages (failed uptime criteria)

**Outcome**: Customer selected us in Week 6 (competitors still had 3-4 weeks left in their pilots)

**Key moves**:
- Shorter timeline gave us first-mover advantage (results before competitors)
- Higher success criteria demonstrated confidence (scared competitors)
- Customer commitment to decision deadline prevented endless evaluation
</example>

<example id="pilot_scope_creep">
**Context**: $500K deal, 30-day pilot agreed, then customer asks to expand scope mid-pilot

**Situation**: Week 2 of pilot, champion says "Can we also test [new use case]?"

**Response**:
- **Acknowledged request**: "I appreciate the interest in expanding scope"
- **Reminded timeline**: "We have 2 weeks left to measure success criteria we agreed on"
- **Offered alternative**: "Let's complete this pilot first. If successful, we can test [new use case] in Phase 2."

**Champion reaction**: "That makes sense. Let's stay focused."

**Outcome**: Pilot completed on time, hit success criteria, expanded use case became part of full contract

**Key moves**:
- Politely declined scope creep (protected timeline)
- Offered alternative (Phase 2) to validate interest
- Kept pilot focused on original success criteria (didn't dilute)

**Pitfall avoided**: Scope creep kills pilot timelines. 30-day pilot becomes 60-day, momentum dies.
</example>

<example id="pilot_failure_recovery">
**Context**: $900K deal, 45-day pilot, success criteria = 75% user adoption, achieved only 60%

**Situation**: Pilot "failed" on paper, but customer still interested

**Diagnosis**:
- **Root cause**: Change management issue (not product issue)
  - Users received only 1-hour training (insufficient)
  - Champion didn't communicate value to team (low buy-in)
- **Product feedback**: Users who adopted loved it (NPS 85 among active users)

**Recovery plan**:
- **Acknowledged gap**: "We didn't hit 75%, but let's understand why"
- **Proposed Phase 2 pilot** (30 days):
  - Increase training to 3 hours + office hours
  - Champion to send weekly email to team (create urgency)
  - Expand pilot to different department (fresh start)

**Phase 2 results**:
- New department: 88% adoption (beat target)
- Original department: 72% adoption (improved but still below target)

**Outcome**: Customer approved $600K contract (scoped down from $900K to reflect adoption reality)

**Key moves**:
- Diagnosed root cause (change management, not product fit)
- Proposed limited Phase 2 (not full re-do)
- Adjusted contract size to match realistic adoption (built trust, didn't oversell)
</example>

<example id="free_pilot_trap">
**Context**: $1M deal, prospect asks for free 90-day pilot with no commitment

**Situation**: Prospect says "We want to test this, but we're not ready to commit yet"

**Red flags**:
- 90 days (too long, deal will drag)
- Free (no customer commitment)
- No decision timeline (open-ended evaluation)

**Pushback**:
- **AE response**: "I'd love to do a pilot, but let's make sure it's set up for success. A few questions:"
  1. "If the pilot succeeds, what's the next step?" (testing if they have budget/authority)
  2. "Who will dedicate time to this pilot?" (testing if they'll allocate resources)
  3. "What's the decision timeline?" (testing urgency)

**Prospect answers**:
1. "We'd need to get board approval after pilot" (no budget authority yet - RED FLAG)
2. "Our team is pretty busy, we'll try to use it when we can" (no resource commitment - RED FLAG)
3. "No specific timeline, we'll see how it goes" (no urgency - RED FLAG)

**Decision**: Declined pilot (too many red flags)

**AE response**: "I appreciate your interest, but I don't think a pilot makes sense yet. Let's first align on budget, decision process, and timeline. Once those are clear, we can structure a focused pilot."

**Outcome**: Prospect ghosted (confirmed this was tire-kicking, not serious evaluation)

**Key moves**:
- Tested customer commitment before investing in pilot (saved 3 months of wasted effort)
- Declined pilot politely (positioned as "setting up for success" not rejection)
- Avoided free pilot trap (pilots without commitment = wasted resources)
</example>
</examples>

<pitfalls>
- **No success criteria**: Vague "let's see if it works" pilots = subjective evaluation, no clear decision
- **Scope creep**: Customer adds requirements mid-pilot = timeline blows out, deal drags
- **Free pilots without commitment**: No customer skin in the game = deprioritized, slow progress
- **Too long**: 90+ day pilots = deal momentum dies, competition catches up
- **No exec sponsor**: Pilot driven by IC or manager = no budget authority, decision delays
- **Pilot as stall tactic**: Customer avoiding decision by requesting pilot = deal will die
</pitfalls>
